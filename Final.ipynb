{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOEp3VLySgdE5dDXaAtpmqm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cUIZzR97SZQi","executionInfo":{"status":"ok","timestamp":1741716348059,"user_tz":-330,"elapsed":976719,"user":{"displayName":"Devapriya Jathin","userId":"00485171850137738167"}},"outputId":"1560851a-1e16-4e63-fb11-5c310e16cf56"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/100\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py:774: UserWarning: Gradients do not exist for variables ['tab_net/attentive_transformer_4/dense_6/kernel', 'tab_net/attentive_transformer_4/dense_6/bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 20ms/step - accuracy: 0.7932 - loss: 0.4169 - val_accuracy: 0.8577 - val_loss: 0.3255\n","Epoch 2/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.8547 - loss: 0.3223 - val_accuracy: 0.8581 - val_loss: 0.3211\n","Epoch 3/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8565 - loss: 0.3109 - val_accuracy: 0.8566 - val_loss: 0.3158\n","Epoch 4/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8584 - loss: 0.3089 - val_accuracy: 0.8574 - val_loss: 0.3141\n","Epoch 5/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8608 - loss: 0.3036 - val_accuracy: 0.8603 - val_loss: 0.3189\n","Epoch 6/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.8608 - loss: 0.2993 - val_accuracy: 0.8606 - val_loss: 0.3155\n","Epoch 7/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8638 - loss: 0.2966 - val_accuracy: 0.8592 - val_loss: 0.3180\n","Epoch 8/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8639 - loss: 0.2915 - val_accuracy: 0.8615 - val_loss: 0.3203\n","Epoch 9/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.8694 - loss: 0.2857 - val_accuracy: 0.8615 - val_loss: 0.3200\n","Epoch 10/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8653 - loss: 0.2891 - val_accuracy: 0.8591 - val_loss: 0.3229\n","Epoch 11/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8707 - loss: 0.2822 - val_accuracy: 0.8591 - val_loss: 0.3183\n","Epoch 12/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.8718 - loss: 0.2794 - val_accuracy: 0.8575 - val_loss: 0.3259\n","Epoch 13/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8754 - loss: 0.2756 - val_accuracy: 0.8591 - val_loss: 0.3192\n","Epoch 14/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.8740 - loss: 0.2748 - val_accuracy: 0.8597 - val_loss: 0.3189\n","Epoch 15/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8754 - loss: 0.2755 - val_accuracy: 0.8560 - val_loss: 0.3242\n","Epoch 16/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8757 - loss: 0.2708 - val_accuracy: 0.8560 - val_loss: 0.3297\n","Epoch 17/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8733 - loss: 0.2724 - val_accuracy: 0.8618 - val_loss: 0.3252\n","Epoch 18/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8769 - loss: 0.2684 - val_accuracy: 0.8574 - val_loss: 0.3374\n","Epoch 19/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.8748 - loss: 0.2663 - val_accuracy: 0.8609 - val_loss: 0.3261\n","Epoch 20/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8784 - loss: 0.2669 - val_accuracy: 0.8620 - val_loss: 0.3333\n","Epoch 21/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8801 - loss: 0.2591 - val_accuracy: 0.8606 - val_loss: 0.3287\n","Epoch 22/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.8737 - loss: 0.2635 - val_accuracy: 0.8618 - val_loss: 0.3209\n","Epoch 23/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8770 - loss: 0.2595 - val_accuracy: 0.8578 - val_loss: 0.3300\n","Epoch 24/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8747 - loss: 0.2692 - val_accuracy: 0.8578 - val_loss: 0.3292\n","Epoch 25/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8784 - loss: 0.2620 - val_accuracy: 0.8591 - val_loss: 0.3327\n","Epoch 26/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8808 - loss: 0.2515 - val_accuracy: 0.8598 - val_loss: 0.3350\n","Epoch 27/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.8796 - loss: 0.2574 - val_accuracy: 0.8597 - val_loss: 0.3317\n","Epoch 28/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8796 - loss: 0.2554 - val_accuracy: 0.8587 - val_loss: 0.3362\n","Epoch 29/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8821 - loss: 0.2552 - val_accuracy: 0.8595 - val_loss: 0.3384\n","Epoch 30/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8821 - loss: 0.2541 - val_accuracy: 0.8604 - val_loss: 0.3380\n","Epoch 31/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8837 - loss: 0.2521 - val_accuracy: 0.8587 - val_loss: 0.3449\n","Epoch 32/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8812 - loss: 0.2503 - val_accuracy: 0.8567 - val_loss: 0.3399\n","Epoch 33/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.8824 - loss: 0.2516 - val_accuracy: 0.8551 - val_loss: 0.3445\n","Epoch 34/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8848 - loss: 0.2457 - val_accuracy: 0.8564 - val_loss: 0.3530\n","Epoch 35/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8842 - loss: 0.2480 - val_accuracy: 0.8577 - val_loss: 0.3468\n","Epoch 36/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8857 - loss: 0.2494 - val_accuracy: 0.8555 - val_loss: 0.3443\n","Epoch 37/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.8857 - loss: 0.2477 - val_accuracy: 0.8555 - val_loss: 0.3376\n","Epoch 38/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8844 - loss: 0.2446 - val_accuracy: 0.8583 - val_loss: 0.3370\n","Epoch 39/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8863 - loss: 0.2399 - val_accuracy: 0.8615 - val_loss: 0.3310\n","Epoch 40/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.8829 - loss: 0.2460 - val_accuracy: 0.8595 - val_loss: 0.3515\n","Epoch 41/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8860 - loss: 0.2446 - val_accuracy: 0.8584 - val_loss: 0.3363\n","Epoch 42/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.8851 - loss: 0.2483 - val_accuracy: 0.8572 - val_loss: 0.3459\n","Epoch 43/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8852 - loss: 0.2483 - val_accuracy: 0.8560 - val_loss: 0.3543\n","Epoch 44/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8841 - loss: 0.2477 - val_accuracy: 0.8574 - val_loss: 0.3477\n","Epoch 45/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8855 - loss: 0.2428 - val_accuracy: 0.8569 - val_loss: 0.3364\n","Epoch 46/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8867 - loss: 0.2417 - val_accuracy: 0.8581 - val_loss: 0.3441\n","Epoch 47/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8849 - loss: 0.2447 - val_accuracy: 0.8606 - val_loss: 0.3582\n","Epoch 48/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8850 - loss: 0.2432 - val_accuracy: 0.8574 - val_loss: 0.3536\n","Epoch 49/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8862 - loss: 0.2410 - val_accuracy: 0.8552 - val_loss: 0.3472\n","Epoch 50/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8867 - loss: 0.2450 - val_accuracy: 0.8581 - val_loss: 0.3482\n","Epoch 51/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.8869 - loss: 0.2393 - val_accuracy: 0.8597 - val_loss: 0.3416\n","Epoch 52/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8902 - loss: 0.2377 - val_accuracy: 0.8567 - val_loss: 0.3541\n","Epoch 53/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.8909 - loss: 0.2391 - val_accuracy: 0.8561 - val_loss: 0.3430\n","Epoch 54/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.8882 - loss: 0.2437 - val_accuracy: 0.8563 - val_loss: 0.3609\n","Epoch 55/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8842 - loss: 0.2437 - val_accuracy: 0.8564 - val_loss: 0.3536\n","Epoch 56/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.8854 - loss: 0.2484 - val_accuracy: 0.8563 - val_loss: 0.3528\n","Epoch 57/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.8928 - loss: 0.2349 - val_accuracy: 0.8567 - val_loss: 0.3520\n","Epoch 58/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8900 - loss: 0.2392 - val_accuracy: 0.8569 - val_loss: 0.3597\n","Epoch 59/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8897 - loss: 0.2337 - val_accuracy: 0.8566 - val_loss: 0.3529\n","Epoch 60/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8897 - loss: 0.2360 - val_accuracy: 0.8540 - val_loss: 0.3418\n","Epoch 61/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8925 - loss: 0.2333 - val_accuracy: 0.8567 - val_loss: 0.3421\n","Epoch 62/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8895 - loss: 0.2395 - val_accuracy: 0.8595 - val_loss: 0.3419\n","Epoch 63/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8897 - loss: 0.2375 - val_accuracy: 0.8574 - val_loss: 0.3542\n","Epoch 64/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8897 - loss: 0.2325 - val_accuracy: 0.8531 - val_loss: 0.3560\n","Epoch 65/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8865 - loss: 0.2401 - val_accuracy: 0.8512 - val_loss: 0.3573\n","Epoch 66/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8887 - loss: 0.2365 - val_accuracy: 0.8589 - val_loss: 0.3510\n","Epoch 67/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8887 - loss: 0.2350 - val_accuracy: 0.8601 - val_loss: 0.3636\n","Epoch 68/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.8928 - loss: 0.2326 - val_accuracy: 0.8606 - val_loss: 0.3549\n","Epoch 69/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8881 - loss: 0.2349 - val_accuracy: 0.8591 - val_loss: 0.3470\n","Epoch 70/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8898 - loss: 0.2342 - val_accuracy: 0.8552 - val_loss: 0.3523\n","Epoch 71/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8896 - loss: 0.2347 - val_accuracy: 0.8566 - val_loss: 0.3652\n","Epoch 72/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8902 - loss: 0.2373 - val_accuracy: 0.8561 - val_loss: 0.3539\n","Epoch 73/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8902 - loss: 0.2354 - val_accuracy: 0.8581 - val_loss: 0.3624\n","Epoch 74/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.8910 - loss: 0.2327 - val_accuracy: 0.8558 - val_loss: 0.3544\n","Epoch 75/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8918 - loss: 0.2328 - val_accuracy: 0.8583 - val_loss: 0.3525\n","Epoch 76/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8908 - loss: 0.2376 - val_accuracy: 0.8572 - val_loss: 0.3509\n","Epoch 77/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.8916 - loss: 0.2328 - val_accuracy: 0.8574 - val_loss: 0.3674\n","Epoch 78/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8861 - loss: 0.2425 - val_accuracy: 0.8580 - val_loss: 0.3572\n","Epoch 79/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8920 - loss: 0.2312 - val_accuracy: 0.8561 - val_loss: 0.3650\n","Epoch 80/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.8965 - loss: 0.2285 - val_accuracy: 0.8578 - val_loss: 0.3570\n","Epoch 81/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8890 - loss: 0.2361 - val_accuracy: 0.8577 - val_loss: 0.3613\n","Epoch 82/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8906 - loss: 0.2318 - val_accuracy: 0.8572 - val_loss: 0.3539\n","Epoch 83/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.8910 - loss: 0.2317 - val_accuracy: 0.8575 - val_loss: 0.3613\n","Epoch 84/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8928 - loss: 0.2305 - val_accuracy: 0.8591 - val_loss: 0.3583\n","Epoch 85/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8924 - loss: 0.2315 - val_accuracy: 0.8571 - val_loss: 0.3536\n","Epoch 86/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.8962 - loss: 0.2279 - val_accuracy: 0.8577 - val_loss: 0.3521\n","Epoch 87/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.8937 - loss: 0.2282 - val_accuracy: 0.8574 - val_loss: 0.3638\n","Epoch 88/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8927 - loss: 0.2306 - val_accuracy: 0.8551 - val_loss: 0.3572\n","Epoch 89/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8964 - loss: 0.2249 - val_accuracy: 0.8549 - val_loss: 0.3511\n","Epoch 90/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8925 - loss: 0.2321 - val_accuracy: 0.8554 - val_loss: 0.3537\n","Epoch 91/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8927 - loss: 0.2276 - val_accuracy: 0.8563 - val_loss: 0.3601\n","Epoch 92/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8888 - loss: 0.2350 - val_accuracy: 0.8569 - val_loss: 0.3481\n","Epoch 93/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8938 - loss: 0.2307 - val_accuracy: 0.8574 - val_loss: 0.3462\n","Epoch 94/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.8923 - loss: 0.2309 - val_accuracy: 0.8578 - val_loss: 0.3471\n","Epoch 95/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8903 - loss: 0.2335 - val_accuracy: 0.8587 - val_loss: 0.3548\n","Epoch 96/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.8925 - loss: 0.2298 - val_accuracy: 0.8572 - val_loss: 0.3531\n","Epoch 97/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8943 - loss: 0.2284 - val_accuracy: 0.8578 - val_loss: 0.3549\n","Epoch 98/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8918 - loss: 0.2278 - val_accuracy: 0.8569 - val_loss: 0.3572\n","Epoch 99/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.8918 - loss: 0.2327 - val_accuracy: 0.8549 - val_loss: 0.3567\n","Epoch 100/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8939 - loss: 0.2327 - val_accuracy: 0.8575 - val_loss: 0.3624\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8613 - loss: 0.3509\n","Test Accuracy: 0.8575\n","Epoch 1/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9023 - loss: 0.2173 - val_accuracy: 0.8595 - val_loss: 0.3615\n","Epoch 2/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8973 - loss: 0.2180 - val_accuracy: 0.8592 - val_loss: 0.3617\n","Epoch 3/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.8985 - loss: 0.2185 - val_accuracy: 0.8598 - val_loss: 0.3604\n","Epoch 4/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.9035 - loss: 0.2101 - val_accuracy: 0.8592 - val_loss: 0.3602\n","Epoch 5/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9000 - loss: 0.2149 - val_accuracy: 0.8600 - val_loss: 0.3614\n","Epoch 6/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.8996 - loss: 0.2202 - val_accuracy: 0.8595 - val_loss: 0.3613\n","Epoch 7/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9025 - loss: 0.2137 - val_accuracy: 0.8603 - val_loss: 0.3614\n","Epoch 8/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9029 - loss: 0.2122 - val_accuracy: 0.8589 - val_loss: 0.3607\n","Epoch 9/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9052 - loss: 0.2096 - val_accuracy: 0.8598 - val_loss: 0.3631\n","Epoch 10/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9034 - loss: 0.2077 - val_accuracy: 0.8594 - val_loss: 0.3641\n","Epoch 11/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9013 - loss: 0.2118 - val_accuracy: 0.8587 - val_loss: 0.3621\n","Epoch 12/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9026 - loss: 0.2115 - val_accuracy: 0.8595 - val_loss: 0.3602\n","Epoch 13/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9006 - loss: 0.2152 - val_accuracy: 0.8586 - val_loss: 0.3641\n","Epoch 14/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.9014 - loss: 0.2152 - val_accuracy: 0.8594 - val_loss: 0.3637\n","Epoch 15/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9046 - loss: 0.2085 - val_accuracy: 0.8587 - val_loss: 0.3650\n","Epoch 16/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9018 - loss: 0.2124 - val_accuracy: 0.8600 - val_loss: 0.3660\n","Epoch 17/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9015 - loss: 0.2114 - val_accuracy: 0.8594 - val_loss: 0.3670\n","Epoch 18/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9024 - loss: 0.2097 - val_accuracy: 0.8586 - val_loss: 0.3670\n","Epoch 19/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.9039 - loss: 0.2078 - val_accuracy: 0.8592 - val_loss: 0.3642\n","Epoch 20/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9033 - loss: 0.2083 - val_accuracy: 0.8586 - val_loss: 0.3652\n","Epoch 21/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.9081 - loss: 0.2025 - val_accuracy: 0.8591 - val_loss: 0.3650\n","Epoch 22/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9048 - loss: 0.2093 - val_accuracy: 0.8587 - val_loss: 0.3659\n","Epoch 23/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9030 - loss: 0.2117 - val_accuracy: 0.8592 - val_loss: 0.3655\n","Epoch 24/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9062 - loss: 0.2073 - val_accuracy: 0.8600 - val_loss: 0.3678\n","Epoch 25/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9076 - loss: 0.2039 - val_accuracy: 0.8595 - val_loss: 0.3684\n","Epoch 26/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9036 - loss: 0.2099 - val_accuracy: 0.8589 - val_loss: 0.3693\n","Epoch 27/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9070 - loss: 0.2025 - val_accuracy: 0.8589 - val_loss: 0.3685\n","Epoch 28/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9032 - loss: 0.2074 - val_accuracy: 0.8591 - val_loss: 0.3675\n","Epoch 29/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.9056 - loss: 0.2047 - val_accuracy: 0.8598 - val_loss: 0.3674\n","Epoch 30/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9054 - loss: 0.2052 - val_accuracy: 0.8587 - val_loss: 0.3686\n","Epoch 31/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9089 - loss: 0.2026 - val_accuracy: 0.8584 - val_loss: 0.3700\n","Epoch 32/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9094 - loss: 0.2025 - val_accuracy: 0.8601 - val_loss: 0.3677\n","Epoch 33/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9064 - loss: 0.2047 - val_accuracy: 0.8603 - val_loss: 0.3696\n","Epoch 34/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9040 - loss: 0.2078 - val_accuracy: 0.8595 - val_loss: 0.3707\n","Epoch 35/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9060 - loss: 0.2051 - val_accuracy: 0.8592 - val_loss: 0.3698\n","Epoch 36/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9060 - loss: 0.2062 - val_accuracy: 0.8595 - val_loss: 0.3702\n","Epoch 37/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9063 - loss: 0.2047 - val_accuracy: 0.8600 - val_loss: 0.3683\n","Epoch 38/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9053 - loss: 0.2068 - val_accuracy: 0.8591 - val_loss: 0.3674\n","Epoch 39/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9051 - loss: 0.2073 - val_accuracy: 0.8594 - val_loss: 0.3717\n","Epoch 40/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9057 - loss: 0.2071 - val_accuracy: 0.8587 - val_loss: 0.3708\n","Epoch 41/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9026 - loss: 0.2103 - val_accuracy: 0.8594 - val_loss: 0.3719\n","Epoch 42/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9060 - loss: 0.2054 - val_accuracy: 0.8584 - val_loss: 0.3758\n","Epoch 43/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9059 - loss: 0.2071 - val_accuracy: 0.8578 - val_loss: 0.3711\n","Epoch 44/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.9050 - loss: 0.2076 - val_accuracy: 0.8574 - val_loss: 0.3674\n","Epoch 45/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9040 - loss: 0.2085 - val_accuracy: 0.8583 - val_loss: 0.3704\n","Epoch 46/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9046 - loss: 0.2033 - val_accuracy: 0.8580 - val_loss: 0.3714\n","Epoch 47/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9029 - loss: 0.2062 - val_accuracy: 0.8592 - val_loss: 0.3738\n","Epoch 48/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9096 - loss: 0.2035 - val_accuracy: 0.8583 - val_loss: 0.3721\n","Epoch 49/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9054 - loss: 0.2041 - val_accuracy: 0.8594 - val_loss: 0.3709\n","Epoch 50/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9047 - loss: 0.2051 - val_accuracy: 0.8597 - val_loss: 0.3743\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8636 - loss: 0.3671\n","Test Accuracy after SGD: 0.8597\n","Saved artifact at '/tmp/tmpm6t1lbrz'. The following endpoints are available:\n","\n","* Endpoint 'serve'\n","  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 100), dtype=tf.float32, name=None)\n","Output Type:\n","  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n","Captures:\n","  135567687313040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687313232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687313616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687314576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687314384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687313808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687314192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687313424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687312464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687315728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687315536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687311120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687315344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687314768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687316496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687315920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687316880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687317264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687314000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687312848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687317840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687317072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687318224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687318032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687318608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687316688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687318416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687319184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687317648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687316304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687314960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567687316112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","Model successfully converted and saved as tabnet_adult_model.tflite\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py:774: UserWarning: Gradients do not exist for variables ['tab_net_1/attentive_transformer_9/dense_18/kernel', 'tab_net_1/attentive_transformer_9/dense_18/bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.7888 - loss: 0.4284 - val_accuracy: 0.8569 - val_loss: 0.3291\n","Epoch 2/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8544 - loss: 0.3269 - val_accuracy: 0.8552 - val_loss: 0.3213\n","Epoch 3/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8548 - loss: 0.3156 - val_accuracy: 0.8552 - val_loss: 0.3201\n","Epoch 4/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.8566 - loss: 0.3120 - val_accuracy: 0.8578 - val_loss: 0.3256\n","Epoch 5/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8597 - loss: 0.3087 - val_accuracy: 0.8548 - val_loss: 0.3215\n","Epoch 6/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8599 - loss: 0.3027 - val_accuracy: 0.8523 - val_loss: 0.3304\n","Epoch 7/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8636 - loss: 0.3025 - val_accuracy: 0.8577 - val_loss: 0.3223\n","Epoch 8/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.8607 - loss: 0.2987 - val_accuracy: 0.8532 - val_loss: 0.3245\n","Epoch 9/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8656 - loss: 0.2933 - val_accuracy: 0.8571 - val_loss: 0.3243\n","Epoch 10/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8705 - loss: 0.2881 - val_accuracy: 0.8591 - val_loss: 0.3214\n","Epoch 11/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8681 - loss: 0.2846 - val_accuracy: 0.8555 - val_loss: 0.3255\n","Epoch 12/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8710 - loss: 0.2855 - val_accuracy: 0.8540 - val_loss: 0.3270\n","Epoch 13/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8681 - loss: 0.2856 - val_accuracy: 0.8558 - val_loss: 0.3295\n","Epoch 14/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.8694 - loss: 0.2817 - val_accuracy: 0.8546 - val_loss: 0.3218\n","Epoch 15/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8677 - loss: 0.2763 - val_accuracy: 0.8557 - val_loss: 0.3248\n","Epoch 16/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.8682 - loss: 0.2799 - val_accuracy: 0.8567 - val_loss: 0.3301\n","Epoch 17/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8672 - loss: 0.2793 - val_accuracy: 0.8563 - val_loss: 0.3339\n","Epoch 18/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8738 - loss: 0.2775 - val_accuracy: 0.8512 - val_loss: 0.3400\n","Epoch 19/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8706 - loss: 0.2748 - val_accuracy: 0.8509 - val_loss: 0.3413\n","Epoch 20/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8693 - loss: 0.2752 - val_accuracy: 0.8555 - val_loss: 0.3305\n","Epoch 21/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8700 - loss: 0.2753 - val_accuracy: 0.8558 - val_loss: 0.3360\n","Epoch 22/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8760 - loss: 0.2688 - val_accuracy: 0.8531 - val_loss: 0.3323\n","Epoch 23/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8759 - loss: 0.2670 - val_accuracy: 0.8538 - val_loss: 0.3337\n","Epoch 24/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.8744 - loss: 0.2706 - val_accuracy: 0.8518 - val_loss: 0.3422\n","Epoch 25/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.8763 - loss: 0.2645 - val_accuracy: 0.8557 - val_loss: 0.3305\n","Epoch 26/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8751 - loss: 0.2696 - val_accuracy: 0.8540 - val_loss: 0.3405\n","Epoch 27/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8841 - loss: 0.2536 - val_accuracy: 0.8508 - val_loss: 0.3311\n","Epoch 28/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8804 - loss: 0.2553 - val_accuracy: 0.8475 - val_loss: 0.3372\n","Epoch 29/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8752 - loss: 0.2678 - val_accuracy: 0.8509 - val_loss: 0.3351\n","Epoch 30/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8774 - loss: 0.2594 - val_accuracy: 0.8518 - val_loss: 0.3323\n","Epoch 31/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.8772 - loss: 0.2639 - val_accuracy: 0.8564 - val_loss: 0.3378\n","Epoch 32/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.8790 - loss: 0.2594 - val_accuracy: 0.8511 - val_loss: 0.3332\n","Epoch 33/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8777 - loss: 0.2603 - val_accuracy: 0.8501 - val_loss: 0.3408\n","Epoch 34/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8794 - loss: 0.2601 - val_accuracy: 0.8538 - val_loss: 0.3342\n","Epoch 35/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8802 - loss: 0.2587 - val_accuracy: 0.8511 - val_loss: 0.3416\n","Epoch 36/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8783 - loss: 0.2549 - val_accuracy: 0.8485 - val_loss: 0.3276\n","Epoch 37/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8822 - loss: 0.2533 - val_accuracy: 0.8494 - val_loss: 0.3421\n","Epoch 38/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8810 - loss: 0.2520 - val_accuracy: 0.8532 - val_loss: 0.3446\n","Epoch 39/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8842 - loss: 0.2509 - val_accuracy: 0.8518 - val_loss: 0.3412\n","Epoch 40/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8786 - loss: 0.2554 - val_accuracy: 0.8546 - val_loss: 0.3517\n","Epoch 41/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8818 - loss: 0.2515 - val_accuracy: 0.8534 - val_loss: 0.3450\n","Epoch 42/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8790 - loss: 0.2563 - val_accuracy: 0.8512 - val_loss: 0.3518\n","Epoch 43/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8828 - loss: 0.2513 - val_accuracy: 0.8511 - val_loss: 0.3459\n","Epoch 44/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8787 - loss: 0.2495 - val_accuracy: 0.8521 - val_loss: 0.3431\n","Epoch 45/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.8807 - loss: 0.2532 - val_accuracy: 0.8529 - val_loss: 0.3423\n","Epoch 46/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.8835 - loss: 0.2471 - val_accuracy: 0.8524 - val_loss: 0.3445\n","Epoch 47/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8818 - loss: 0.2480 - val_accuracy: 0.8512 - val_loss: 0.3429\n","Epoch 48/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8812 - loss: 0.2517 - val_accuracy: 0.8514 - val_loss: 0.3458\n","Epoch 49/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.8834 - loss: 0.2475 - val_accuracy: 0.8521 - val_loss: 0.3385\n","Epoch 50/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.8818 - loss: 0.2477 - val_accuracy: 0.8534 - val_loss: 0.3515\n","Epoch 51/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8834 - loss: 0.2469 - val_accuracy: 0.8574 - val_loss: 0.3462\n","Epoch 52/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8837 - loss: 0.2425 - val_accuracy: 0.8524 - val_loss: 0.3454\n","Epoch 53/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8840 - loss: 0.2459 - val_accuracy: 0.8497 - val_loss: 0.3490\n","Epoch 54/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.8865 - loss: 0.2418 - val_accuracy: 0.8503 - val_loss: 0.3418\n","Epoch 55/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8851 - loss: 0.2459 - val_accuracy: 0.8520 - val_loss: 0.3547\n","Epoch 56/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8842 - loss: 0.2497 - val_accuracy: 0.8564 - val_loss: 0.3446\n","Epoch 57/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.8874 - loss: 0.2386 - val_accuracy: 0.8509 - val_loss: 0.3438\n","Epoch 58/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.8835 - loss: 0.2434 - val_accuracy: 0.8498 - val_loss: 0.3510\n","Epoch 59/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8859 - loss: 0.2404 - val_accuracy: 0.8543 - val_loss: 0.3626\n","Epoch 60/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8856 - loss: 0.2437 - val_accuracy: 0.8529 - val_loss: 0.3580\n","Epoch 61/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8854 - loss: 0.2421 - val_accuracy: 0.8544 - val_loss: 0.3481\n","Epoch 62/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8890 - loss: 0.2370 - val_accuracy: 0.8495 - val_loss: 0.3500\n","Epoch 63/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.8895 - loss: 0.2348 - val_accuracy: 0.8523 - val_loss: 0.3507\n","Epoch 64/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8873 - loss: 0.2388 - val_accuracy: 0.8515 - val_loss: 0.3567\n","Epoch 65/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8848 - loss: 0.2420 - val_accuracy: 0.8498 - val_loss: 0.3490\n","Epoch 66/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8845 - loss: 0.2445 - val_accuracy: 0.8529 - val_loss: 0.3495\n","Epoch 67/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8852 - loss: 0.2422 - val_accuracy: 0.8501 - val_loss: 0.3512\n","Epoch 68/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8876 - loss: 0.2417 - val_accuracy: 0.8509 - val_loss: 0.3511\n","Epoch 69/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8858 - loss: 0.2402 - val_accuracy: 0.8524 - val_loss: 0.3515\n","Epoch 70/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.8853 - loss: 0.2391 - val_accuracy: 0.8523 - val_loss: 0.3473\n","Epoch 71/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.8899 - loss: 0.2359 - val_accuracy: 0.8534 - val_loss: 0.3520\n","Epoch 72/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8889 - loss: 0.2393 - val_accuracy: 0.8534 - val_loss: 0.3539\n","Epoch 73/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8835 - loss: 0.2413 - val_accuracy: 0.8524 - val_loss: 0.3545\n","Epoch 74/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8897 - loss: 0.2362 - val_accuracy: 0.8492 - val_loss: 0.3443\n","Epoch 75/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8919 - loss: 0.2302 - val_accuracy: 0.8512 - val_loss: 0.3575\n","Epoch 76/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.8873 - loss: 0.2379 - val_accuracy: 0.8534 - val_loss: 0.3293\n","Epoch 77/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8848 - loss: 0.2466 - val_accuracy: 0.8486 - val_loss: 0.3577\n","Epoch 78/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8887 - loss: 0.2362 - val_accuracy: 0.8531 - val_loss: 0.3524\n","Epoch 79/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8876 - loss: 0.2368 - val_accuracy: 0.8515 - val_loss: 0.3549\n","Epoch 80/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8899 - loss: 0.2362 - val_accuracy: 0.8506 - val_loss: 0.3542\n","Epoch 81/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.8871 - loss: 0.2390 - val_accuracy: 0.8552 - val_loss: 0.3534\n","Epoch 82/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8850 - loss: 0.2389 - val_accuracy: 0.8523 - val_loss: 0.3499\n","Epoch 83/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.8886 - loss: 0.2367 - val_accuracy: 0.8528 - val_loss: 0.3487\n","Epoch 84/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8865 - loss: 0.2367 - val_accuracy: 0.8532 - val_loss: 0.3603\n","Epoch 85/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8938 - loss: 0.2309 - val_accuracy: 0.8524 - val_loss: 0.3560\n","Epoch 86/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8908 - loss: 0.2345 - val_accuracy: 0.8523 - val_loss: 0.3648\n","Epoch 87/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.8915 - loss: 0.2311 - val_accuracy: 0.8541 - val_loss: 0.3560\n","Epoch 88/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8831 - loss: 0.2382 - val_accuracy: 0.8531 - val_loss: 0.3591\n","Epoch 89/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8881 - loss: 0.2335 - val_accuracy: 0.8546 - val_loss: 0.3574\n","Epoch 90/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.8881 - loss: 0.2325 - val_accuracy: 0.8544 - val_loss: 0.3643\n","Epoch 91/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8867 - loss: 0.2360 - val_accuracy: 0.8537 - val_loss: 0.3492\n","Epoch 92/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.8894 - loss: 0.2347 - val_accuracy: 0.8540 - val_loss: 0.3689\n","Epoch 93/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8902 - loss: 0.2323 - val_accuracy: 0.8538 - val_loss: 0.3567\n","Epoch 94/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.8893 - loss: 0.2342 - val_accuracy: 0.8532 - val_loss: 0.3644\n","Epoch 95/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.8868 - loss: 0.2384 - val_accuracy: 0.8523 - val_loss: 0.3626\n","Epoch 96/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8873 - loss: 0.2328 - val_accuracy: 0.8531 - val_loss: 0.3546\n","Epoch 97/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.8904 - loss: 0.2327 - val_accuracy: 0.8549 - val_loss: 0.3573\n","Epoch 98/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.8829 - loss: 0.2389 - val_accuracy: 0.8563 - val_loss: 0.3561\n","Epoch 99/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8917 - loss: 0.2324 - val_accuracy: 0.8529 - val_loss: 0.3629\n","Epoch 100/100\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8855 - loss: 0.2344 - val_accuracy: 0.8497 - val_loss: 0.3643\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8494 - loss: 0.3602\n","Test Accuracy: 0.8497\n","Epoch 1/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.8909 - loss: 0.2275 - val_accuracy: 0.8520 - val_loss: 0.3674\n","Epoch 2/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8926 - loss: 0.2243 - val_accuracy: 0.8508 - val_loss: 0.3699\n","Epoch 3/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8935 - loss: 0.2235 - val_accuracy: 0.8526 - val_loss: 0.3710\n","Epoch 4/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8942 - loss: 0.2200 - val_accuracy: 0.8534 - val_loss: 0.3711\n","Epoch 5/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8948 - loss: 0.2188 - val_accuracy: 0.8521 - val_loss: 0.3758\n","Epoch 6/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8921 - loss: 0.2203 - val_accuracy: 0.8518 - val_loss: 0.3792\n","Epoch 7/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8958 - loss: 0.2155 - val_accuracy: 0.8517 - val_loss: 0.3809\n","Epoch 8/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8941 - loss: 0.2168 - val_accuracy: 0.8517 - val_loss: 0.3842\n","Epoch 9/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8988 - loss: 0.2108 - val_accuracy: 0.8521 - val_loss: 0.3805\n","Epoch 10/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.8952 - loss: 0.2151 - val_accuracy: 0.8537 - val_loss: 0.3860\n","Epoch 11/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8971 - loss: 0.2127 - val_accuracy: 0.8537 - val_loss: 0.3836\n","Epoch 12/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8946 - loss: 0.2146 - val_accuracy: 0.8537 - val_loss: 0.3823\n","Epoch 13/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8937 - loss: 0.2199 - val_accuracy: 0.8535 - val_loss: 0.3837\n","Epoch 14/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.8969 - loss: 0.2148 - val_accuracy: 0.8531 - val_loss: 0.3878\n","Epoch 15/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8992 - loss: 0.2097 - val_accuracy: 0.8534 - val_loss: 0.3886\n","Epoch 16/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8972 - loss: 0.2152 - val_accuracy: 0.8528 - val_loss: 0.3898\n","Epoch 17/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8961 - loss: 0.2133 - val_accuracy: 0.8531 - val_loss: 0.3888\n","Epoch 18/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8981 - loss: 0.2126 - val_accuracy: 0.8541 - val_loss: 0.3886\n","Epoch 19/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8926 - loss: 0.2166 - val_accuracy: 0.8543 - val_loss: 0.3905\n","Epoch 20/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.8958 - loss: 0.2162 - val_accuracy: 0.8538 - val_loss: 0.3915\n","Epoch 21/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.8991 - loss: 0.2107 - val_accuracy: 0.8517 - val_loss: 0.3942\n","Epoch 22/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8959 - loss: 0.2126 - val_accuracy: 0.8543 - val_loss: 0.3958\n","Epoch 23/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8990 - loss: 0.2120 - val_accuracy: 0.8532 - val_loss: 0.3950\n","Epoch 24/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8982 - loss: 0.2144 - val_accuracy: 0.8540 - val_loss: 0.3941\n","Epoch 25/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8963 - loss: 0.2144 - val_accuracy: 0.8554 - val_loss: 0.3949\n","Epoch 26/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8980 - loss: 0.2121 - val_accuracy: 0.8552 - val_loss: 0.3952\n","Epoch 27/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9002 - loss: 0.2065 - val_accuracy: 0.8541 - val_loss: 0.3934\n","Epoch 28/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8958 - loss: 0.2114 - val_accuracy: 0.8549 - val_loss: 0.3955\n","Epoch 29/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8968 - loss: 0.2135 - val_accuracy: 0.8524 - val_loss: 0.3973\n","Epoch 30/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.8976 - loss: 0.2112 - val_accuracy: 0.8537 - val_loss: 0.3972\n","Epoch 31/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8981 - loss: 0.2100 - val_accuracy: 0.8537 - val_loss: 0.3973\n","Epoch 32/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9012 - loss: 0.2069 - val_accuracy: 0.8535 - val_loss: 0.3992\n","Epoch 33/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.8977 - loss: 0.2130 - val_accuracy: 0.8540 - val_loss: 0.3982\n","Epoch 34/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9012 - loss: 0.2066 - val_accuracy: 0.8535 - val_loss: 0.3973\n","Epoch 35/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8979 - loss: 0.2132 - val_accuracy: 0.8537 - val_loss: 0.3980\n","Epoch 36/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8985 - loss: 0.2115 - val_accuracy: 0.8532 - val_loss: 0.4019\n","Epoch 37/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8946 - loss: 0.2121 - val_accuracy: 0.8546 - val_loss: 0.3965\n","Epoch 38/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.8986 - loss: 0.2088 - val_accuracy: 0.8537 - val_loss: 0.3988\n","Epoch 39/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9012 - loss: 0.2065 - val_accuracy: 0.8540 - val_loss: 0.4014\n","Epoch 40/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8982 - loss: 0.2114 - val_accuracy: 0.8543 - val_loss: 0.4015\n","Epoch 41/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9032 - loss: 0.2049 - val_accuracy: 0.8529 - val_loss: 0.4030\n","Epoch 42/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9008 - loss: 0.2081 - val_accuracy: 0.8534 - val_loss: 0.3995\n","Epoch 43/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.8995 - loss: 0.2086 - val_accuracy: 0.8543 - val_loss: 0.4018\n","Epoch 44/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8990 - loss: 0.2090 - val_accuracy: 0.8534 - val_loss: 0.4016\n","Epoch 45/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9007 - loss: 0.2071 - val_accuracy: 0.8534 - val_loss: 0.4029\n","Epoch 46/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8959 - loss: 0.2118 - val_accuracy: 0.8541 - val_loss: 0.4027\n","Epoch 47/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.8987 - loss: 0.2058 - val_accuracy: 0.8538 - val_loss: 0.4039\n","Epoch 48/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8987 - loss: 0.2113 - val_accuracy: 0.8544 - val_loss: 0.4037\n","Epoch 49/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9002 - loss: 0.2088 - val_accuracy: 0.8535 - val_loss: 0.4043\n","Epoch 50/50\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8985 - loss: 0.2120 - val_accuracy: 0.8534 - val_loss: 0.4052\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8546 - loss: 0.4047\n","Test Accuracy after SGD: 0.8534\n","Saved artifact at '/tmp/tmpxrtf2skq'. The following endpoints are available:\n","\n","* Endpoint 'serve'\n","  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 100), dtype=tf.float32, name=None)\n","Output Type:\n","  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n","Captures:\n","  135567640854352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567640841296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638512080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638513040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567640841872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567640843024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638512464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638511696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638512848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638514192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638514000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638511888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638513808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638513232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638514960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638514384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638515344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638515728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638512656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638512272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638516304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638515536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638516688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638516496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638517072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638515152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638516880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638517648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638516112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638515920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638518032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638517840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","Model successfully converted and saved as tabnet_adult_model.tflite\n","Saved artifact at '/tmp/tmp_8obstd4'. The following endpoints are available:\n","\n","* Endpoint 'serve'\n","  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 100), dtype=tf.float32, name=None)\n","Output Type:\n","  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n","Captures:\n","  135567640854352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567640841296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638512080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638513040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567640841872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567640843024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638512464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638511696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638512848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638514192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638514000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638511888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638513808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638513232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638514960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638514384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638515344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638515728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638512656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638512272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638516304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638515536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638516688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638516496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638517072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638515152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638516880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638517648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638516112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638515920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638518032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638517840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","Quantized TFLite model successfully saved as tabnet_adult_model_quantized.tflite\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Layer, Dense, BatchNormalization, Dropout\n","from tensorflow.keras.models import Model\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","\n","# Load dataset\n","url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n","columns = [\n","    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n","    \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n","    \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"\n","]\n","df = pd.read_csv(url, names=columns, na_values=\" ?\", skipinitialspace=True)\n","\n","# Drop missing values\n","df.dropna(inplace=True)\n","\n","# Separate features and target\n","X = df.drop(columns=[\"income\"])\n","y = df[\"income\"]\n","\n","# Encode target variable\n","le = LabelEncoder()\n","y = le.fit_transform(y)  # Convert to 0 (<=50K) and 1 (>50K)\n","\n","# Identify categorical and numerical columns\n","categorical_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n","numerical_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n","\n","# Encode categorical features (one-hot encoding)\n","X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n","\n","# Standardize numerical columns\n","scaler = StandardScaler()\n","X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n","\n","# Convert to numpy arrays\n","X = X.values.astype(np.float32)\n","y = y.astype(np.int32)\n","\n","# Split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","\n","# Get input dimension\n","input_dim = X_train.shape[1]\n","\n","# SparseMax Activation\n","class SparseMax(Layer):\n","    def call(self, inputs):\n","        logits_sorted = tf.sort(inputs, direction=\"DESCENDING\")\n","        cumulative_sum = tf.cumsum(logits_sorted, axis=-1)\n","        k = tf.range(1, tf.shape(inputs)[-1] + 1, dtype=tf.float32)\n","        condition = logits_sorted - (cumulative_sum - 1) / k\n","        k_max = tf.reduce_sum(tf.cast(condition > 0, tf.float32), axis=-1, keepdims=True)\n","        threshold = (tf.reduce_sum(logits_sorted * tf.cast(condition > 0, tf.float32), axis=-1, keepdims=True) - 1) / k_max\n","        return tf.maximum(inputs - threshold, 0)\n","\n","# Feature Transformer (Fix: Match output_dim to input_dim for residual connection)\n","class FeatureTransformer(Layer):\n","    def __init__(self, input_dim):\n","        super(FeatureTransformer, self).__init__()\n","        self.fc1 = Dense(input_dim, activation=None)  # Match input_dim\n","        self.bn1 = BatchNormalization()\n","        self.fc2 = Dense(input_dim, activation=None)  # Match input_dim\n","        self.bn2 = BatchNormalization()\n","        self.dropout = Dropout(0.2)\n","\n","    def call(self, inputs):\n","        x = self.fc1(inputs)\n","        x = self.bn1(x)\n","        x = tf.nn.relu(x)\n","        x = self.fc2(x)\n","        x = self.bn2(x)\n","        x = tf.nn.relu(x)\n","        return self.dropout(x) + inputs  # Residual connection now works\n","\n","# Attentive Transformer (Feature Selection)\n","class AttentiveTransformer(Layer):\n","    def __init__(self, input_dim):\n","        super(AttentiveTransformer, self).__init__()\n","        self.fc = Dense(input_dim, activation=None)\n","        self.sparsemax = SparseMax()\n","\n","    def call(self, inputs, prior):\n","        x = self.fc(inputs)\n","        x = self.sparsemax(x * prior)  # Apply prior mask\n","        return x\n","\n","# TabNet Model\n","class TabNet(Model):\n","    def __init__(self, input_dim, output_dim, num_steps=5, gamma=1.5):\n","        super(TabNet, self).__init__()\n","        self.num_steps = num_steps\n","        self.gamma = gamma\n","\n","        # Initial shared feature transformer\n","        self.shared_ft = FeatureTransformer(input_dim)  # Fix: Match input_dim\n","\n","        # Attentive transformers per step\n","        self.attentive_trans = [AttentiveTransformer(input_dim) for _ in range(num_steps)]\n","\n","        # Decision layers per step\n","        self.decision_layers = [Dense(output_dim, activation=\"softmax\") for _ in range(num_steps)]\n","\n","    def call(self, inputs):\n","        batch_size = tf.shape(inputs)[0]\n","        prior = tf.ones((batch_size, inputs.shape[1]))  # Initial prior\n","\n","        aggregated_output = 0\n","        masked_inputs = inputs\n","\n","        for i in range(self.num_steps):\n","            transformed_features = self.shared_ft(masked_inputs)\n","            mask = self.attentive_trans[i](inputs, prior)  # Fix: Corrected input to mask selection\n","            masked_inputs = mask * inputs  # Apply mask to raw input\n","\n","            # Aggregate decision outputs using weighted sum\n","            decision_out = self.decision_layers[i](transformed_features)\n","            aggregated_output += decision_out / self.num_steps  # Averaging effect\n","\n","            # Update feature prior (increase importance of selected features)\n","            prior = self.gamma * (prior - mask)\n","\n","        return aggregated_output\n","\n","# Create TabNet Model\n","output_dim = 2  # Binary classification (<=50K or >50K)\n","tabnet = TabNet(input_dim, output_dim, num_steps=5)\n","\n","# Compile Model with AdamW optimizer and lower learning rate\n","tabnet.compile(\n","    optimizer=tf.keras.optimizers.AdamW(learning_rate=0.005),\n","    loss=\"sparse_categorical_crossentropy\",\n","    metrics=[\"accuracy\"]\n",")\n","\n","# Train the model\n","history = tabnet.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=128)\n","\n","# Evaluate the model\n","test_loss, test_acc = tabnet.evaluate(X_test, y_test)\n","print(f\"Test Accuracy: {test_acc:.4f}\")\n","\n","# Save the model\n","tabnet.save(\"tabnet_adult_model.keras\")\n","\n","#to save this model into a tf lite model\n","import tensorflow as tf\n","\n","# Recompile the model with SGD optimizer\n","tabnet.compile(\n","    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n","    loss=\"sparse_categorical_crossentropy\",\n","    metrics=[\"accuracy\"]\n",")\n","\n","# Retrain the model using SGD\n","history = tabnet.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=128)\n","\n","# Evaluate the retrained model\n","test_loss, test_acc = tabnet.evaluate(X_test, y_test)\n","print(f\"Test Accuracy after SGD: {test_acc:.4f}\")\n","\n","# Convert to TensorFlow Lite\n","converter = tf.lite.TFLiteConverter.from_keras_model(tabnet)\n","tflite_model = converter.convert()\n","\n","# Save the TFLite model\n","with open(\"tabnet_adult_model.tflite\", \"wb\") as f:\n","    f.write(tflite_model)\n","\n","print(\"Model successfully converted and saved as tabnet_adult_model.tflite\")\n","\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Layer, Dense, BatchNormalization, Dropout\n","from tensorflow.keras.models import Model\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","\n","# Load dataset\n","url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n","columns = [\n","    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n","    \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n","    \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"\n","]\n","df = pd.read_csv(url, names=columns, na_values=\" ?\", skipinitialspace=True)\n","\n","# Drop missing values\n","df.dropna(inplace=True)\n","\n","# Separate features and target\n","X = df.drop(columns=[\"income\"])\n","y = df[\"income\"]\n","\n","# Encode target variable\n","le = LabelEncoder()\n","y = le.fit_transform(y)  # Convert to 0 (<=50K) and 1 (>50K)\n","\n","# Identify categorical and numerical columns\n","categorical_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n","numerical_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n","\n","# Encode categorical features (one-hot encoding)\n","X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n","\n","# Standardize numerical columns\n","scaler = StandardScaler()\n","X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n","\n","# Convert to numpy arrays\n","X = X.values.astype(np.float32)\n","y = y.astype(np.int32)\n","\n","# Split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","\n","# Get input dimension\n","input_dim = X_train.shape[1]\n","\n","# SparseMax Activation\n","class SparseMax(Layer):\n","    def call(self, inputs):\n","        logits_sorted = tf.sort(inputs, direction=\"DESCENDING\")\n","        cumulative_sum = tf.cumsum(logits_sorted, axis=-1)\n","        k = tf.range(1, tf.shape(inputs)[-1] + 1, dtype=tf.float32)\n","        condition = logits_sorted - (cumulative_sum - 1) / k\n","        k_max = tf.reduce_sum(tf.cast(condition > 0, tf.float32), axis=-1, keepdims=True)\n","        threshold = (tf.reduce_sum(logits_sorted * tf.cast(condition > 0, tf.float32), axis=-1, keepdims=True) - 1) / k_max\n","        return tf.maximum(inputs - threshold, 0)\n","\n","# Feature Transformer (Fix: Match output_dim to input_dim for residual connection)\n","class FeatureTransformer(Layer):\n","    def __init__(self, input_dim):\n","        super(FeatureTransformer, self).__init__()\n","        self.fc1 = Dense(input_dim, activation=None)  # Match input_dim\n","        self.bn1 = BatchNormalization()\n","        self.fc2 = Dense(input_dim, activation=None)  # Match input_dim\n","        self.bn2 = BatchNormalization()\n","        self.dropout = Dropout(0.2)\n","\n","    def call(self, inputs):\n","        x = self.fc1(inputs)\n","        x = self.bn1(x)\n","        x = tf.nn.relu(x)\n","        x = self.fc2(x)\n","        x = self.bn2(x)\n","        x = tf.nn.relu(x)\n","        return self.dropout(x) + inputs  # Residual connection now works\n","\n","# Attentive Transformer (Feature Selection)\n","class AttentiveTransformer(Layer):\n","    def __init__(self, input_dim):\n","        super(AttentiveTransformer, self).__init__()\n","        self.fc = Dense(input_dim, activation=None)\n","        self.sparsemax = SparseMax()\n","\n","    def call(self, inputs, prior):\n","        x = self.fc(inputs)\n","        x = self.sparsemax(x * prior)  # Apply prior mask\n","        return x\n","\n","# TabNet Model\n","class TabNet(Model):\n","    def __init__(self, input_dim, output_dim, num_steps=5, gamma=1.5):\n","        super(TabNet, self).__init__()\n","        self.num_steps = num_steps\n","        self.gamma = gamma\n","\n","        # Initial shared feature transformer\n","        self.shared_ft = FeatureTransformer(input_dim)  # Fix: Match input_dim\n","\n","        # Attentive transformers per step\n","        self.attentive_trans = [AttentiveTransformer(input_dim) for _ in range(num_steps)]\n","\n","        # Decision layers per step\n","        self.decision_layers = [Dense(output_dim, activation=\"softmax\") for _ in range(num_steps)]\n","\n","    def call(self, inputs):\n","        batch_size = tf.shape(inputs)[0]\n","        prior = tf.ones((batch_size, inputs.shape[1]))  # Initial prior\n","\n","        aggregated_output = 0\n","        masked_inputs = inputs\n","\n","        for i in range(self.num_steps):\n","            transformed_features = self.shared_ft(masked_inputs)\n","            mask = self.attentive_trans[i](inputs, prior)  # Fix: Corrected input to mask selection\n","            masked_inputs = mask * inputs  # Apply mask to raw input\n","\n","            # Aggregate decision outputs using weighted sum\n","            decision_out = self.decision_layers[i](transformed_features)\n","            aggregated_output += decision_out / self.num_steps  # Averaging effect\n","\n","            # Update feature prior (increase importance of selected features)\n","            prior = self.gamma * (prior - mask)\n","\n","        return aggregated_output\n","\n","# Create TabNet Model\n","output_dim = 2  # Binary classification (<=50K or >50K)\n","tabnet = TabNet(input_dim, output_dim, num_steps=5)\n","\n","# Compile Model with AdamW optimizer and lower learning rate\n","tabnet.compile(\n","    optimizer=tf.keras.optimizers.AdamW(learning_rate=0.005),\n","    loss=\"sparse_categorical_crossentropy\",\n","    metrics=[\"accuracy\"]\n",")\n","\n","# Train the model\n","history = tabnet.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=128)\n","\n","# Evaluate the model\n","test_loss, test_acc = tabnet.evaluate(X_test, y_test)\n","print(f\"Test Accuracy: {test_acc:.4f}\")\n","\n","# Save the model\n","tabnet.save(\"tabnet_adult_model.keras\")\n","\n","#to save this model into a tf lite model\n","import tensorflow as tf\n","\n","# Recompile the model with SGD optimizer\n","tabnet.compile(\n","    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n","    loss=\"sparse_categorical_crossentropy\",\n","    metrics=[\"accuracy\"]\n",")\n","\n","# Retrain the model using SGD\n","history = tabnet.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=128)\n","\n","# Evaluate the retrained model\n","test_loss, test_acc = tabnet.evaluate(X_test, y_test)\n","print(f\"Test Accuracy after SGD: {test_acc:.4f}\")\n","\n","# Convert to TensorFlow Lite\n","converter = tf.lite.TFLiteConverter.from_keras_model(tabnet)\n","tflite_model = converter.convert()\n","\n","# Save the TFLite model\n","with open(\"tabnet_adult_model.tflite\", \"wb\") as f:\n","    f.write(tflite_model)\n","\n","print(\"Model successfully converted and saved as tabnet_adult_model.tflite\")\n","\n","import tensorflow as tf\n","import numpy as np\n","\n","# Convert the trained model to TensorFlow Lite with Post-Training Quantization\n","converter = tf.lite.TFLiteConverter.from_keras_model(tabnet)\n","\n","# Enable float16 quantization (reduces model size while maintaining accuracy)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","converter.target_spec.supported_types = [tf.float16]\n","\n","# Convert the model\n","quantized_tflite_model = converter.convert()\n","\n","# Save the quantized TFLite model\n","with open(\"tabnet_adult_model_quantized.tflite\", \"wb\") as f:\n","    f.write(quantized_tflite_model)\n","\n","print(\"Quantized TFLite model successfully saved as tabnet_adult_model_quantized.tflite\")"]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","# Load the quantized model\n","interpreter = tf.lite.Interpreter(model_path=\"tabnet_adult_model_quantized.tflite\")\n","interpreter.allocate_tensors()\n","\n","# Get input and output details\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","\n","# Function to make predictions using TFLite model\n","def predict_tflite(interpreter, X_test):\n","    predictions = []\n","    for i in range(len(X_test)):\n","        input_data = np.expand_dims(X_test[i], axis=0).astype(np.float32)  # Ensure correct dtype\n","        interpreter.set_tensor(input_details[0]['index'], input_data)\n","        interpreter.invoke()\n","        output_data = interpreter.get_tensor(output_details[0]['index'])\n","        predictions.append(np.argmax(output_data))  # Get class with highest probability\n","    return np.array(predictions)\n","\n","# Run inference\n","y_pred_tflite = predict_tflite(interpreter, X_test)\n","\n","# Calculate accuracy\n","accuracy_tflite = np.mean(y_pred_tflite == y_test)\n","print(f\"Post-Training Quantization Model Accuracy: {accuracy_tflite:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ievt-rS2ZRoB","executionInfo":{"status":"ok","timestamp":1741716533162,"user_tz":-330,"elapsed":1374,"user":{"displayName":"Devapriya Jathin","userId":"00485171850137738167"}},"outputId":"63114bf7-4cd2-4c0b-bce5-b3a818a17642"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Post-Training Quantization Model Accuracy: 0.8532\n"]}]},{"cell_type":"code","source":["!ls /content/\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-G4WDlqubM1I","executionInfo":{"status":"ok","timestamp":1741717035700,"user_tz":-330,"elapsed":96,"user":{"displayName":"Devapriya Jathin","userId":"00485171850137738167"}},"outputId":"40b9c146-e2a3-4125-c253-d692c02361f9"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["sample_data\t\t  tabnet_adult_model_quantized.tflite\n","tabnet_adult_model.keras  tabnet_adult_model.tflite\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"tabnet_adult_model_quantized.tflite\")\n","\n","from google.colab import files\n","files.download(\"tabnet_adult_model.tflite\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"qdfgt0H9brOn","executionInfo":{"status":"ok","timestamp":1741717195801,"user_tz":-330,"elapsed":53,"user":{"displayName":"Devapriya Jathin","userId":"00485171850137738167"}},"outputId":"47341079-cd4e-4ae5-d730-0232b9d3af74"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_4e719b8c-4e91-4a6c-a303-0ec6a3ffe24a\", \"tabnet_adult_model_quantized.tflite\", 151768)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_6fd20667-fdcd-473e-ac18-0545815e311e\", \"tabnet_adult_model.tflite\", 272176)"]},"metadata":{}}]},{"cell_type":"code","source":["import os\n","\n","# Evaluate original model accuracy\n","test_loss, test_acc = tabnet.evaluate(X_test, y_test)\n","print(f\"Test Accuracy before Post-Training Quantization: {test_acc:.4f}\")\n","\n","# Load the quantized TFLite model and evaluate accuracy\n","interpreter = tf.lite.Interpreter(model_path=\"tabnet_adult_model_quantized.tflite\")\n","interpreter.allocate_tensors()\n","\n","# Get input and output details\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","\n","# Function to run inference on TFLite model\n","def evaluate_tflite_model(interpreter, X_test, y_test):\n","    correct_predictions = 0\n","    total_samples = len(y_test)\n","\n","    for i in range(total_samples):\n","        # Preprocess input\n","        input_data = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","\n","        # Set input tensor\n","        interpreter.set_tensor(input_details[0]['index'], input_data)\n","\n","        # Run inference\n","        interpreter.invoke()\n","\n","        # Get output tensor\n","        output_data = interpreter.get_tensor(output_details[0]['index'])\n","        predicted_label = np.argmax(output_data)\n","\n","        # Check if prediction is correct\n","        if predicted_label == y_test[i]:\n","            correct_predictions += 1\n","\n","    return correct_predictions / total_samples\n","\n","# Compute accuracy of quantized TFLite model\n","quantized_acc = evaluate_tflite_model(interpreter, X_test, y_test)\n","print(f\"Test Accuracy after Post-Training Quantization: {quantized_acc:.4f}\")\n","\n","# Get file sizes\n","tflite_model_size = os.path.getsize(\"tabnet_adult_model.tflite\") / 1024  # in KB\n","quantized_tflite_model_size = os.path.getsize(\"tabnet_adult_model_quantized.tflite\") / 1024  # in KB\n","\n","print(f\"Original TFLite Model Size: {tflite_model_size:.2f} KB\")\n","print(f\"Quantized TFLite Model Size: {quantized_tflite_model_size:.2f} KB\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VmuwkRlfg9PP","executionInfo":{"status":"ok","timestamp":1741718549531,"user_tz":-330,"elapsed":3627,"user":{"displayName":"Devapriya Jathin","userId":"00485171850137738167"}},"outputId":"1da4758b-bda6-463b-ba74-666e08ebaf7d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8546 - loss: 0.4047\n","Test Accuracy before Post-Training Quantization: 0.8534\n","Test Accuracy after Post-Training Quantization: 0.8532\n","Original TFLite Model Size: 265.80 KB\n","Quantized TFLite Model Size: 148.21 KB\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import os\n","\n","# Convert the trained model to TensorFlow Lite with Post-Training Quantization\n","converter = tf.lite.TFLiteConverter.from_keras_model(tabnet)\n","\n","# Enable float16 quantization (reduces model size while maintaining accuracy)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","converter.target_spec.supported_types = [tf.float16]\n","\n","# Convert the model\n","quantized_tflite_model = converter.convert()\n","\n","# Save the quantized TFLite model\n","with open(\"tabnet_adult_model_quantized.tflite\", \"wb\") as f:\n","    f.write(quantized_tflite_model)\n","\n","print(\"Quantized TFLite model successfully saved as tabnet_adult_model_quantized.tflite\")\n","\n","# Evaluate original model accuracy and loss\n","test_loss, test_acc = tabnet.evaluate(X_test, y_test)\n","print(f\"Test Accuracy before Post-Training Quantization: {test_acc:.4f}\")\n","print(f\"Test Loss before Post-Training Quantization: {test_loss:.4f}\")\n","\n","# Load the quantized TFLite model and evaluate accuracy\n","interpreter = tf.lite.Interpreter(model_path=\"tabnet_adult_model_quantized.tflite\")\n","interpreter.allocate_tensors()\n","\n","# Get input and output details\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","\n","# Function to run inference on TFLite model\n","def evaluate_tflite_model(interpreter, X_test, y_test):\n","    correct_predictions = 0\n","    total_samples = len(y_test)\n","\n","    for i in range(total_samples):\n","        # Preprocess input\n","        input_data = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n","\n","        # Set input tensor\n","        interpreter.set_tensor(input_details[0]['index'], input_data)\n","\n","        # Run inference\n","        interpreter.invoke()\n","\n","        # Get output tensor\n","        output_data = interpreter.get_tensor(output_details[0]['index'])\n","        predicted_label = np.argmax(output_data)\n","\n","        # Check if prediction is correct\n","        if predicted_label == y_test[i]:\n","            correct_predictions += 1\n","\n","    return correct_predictions / total_samples\n","\n","# Compute accuracy of quantized TFLite model\n","quantized_acc = evaluate_tflite_model(interpreter, X_test, y_test)\n","print(f\"Test Accuracy after Post-Training Quantization: {quantized_acc:.4f}\")\n","\n","# Get file sizes\n","tflite_model_size = os.path.getsize(\"tabnet_adult_model.tflite\") / 1024  # in KB\n","quantized_tflite_model_size = os.path.getsize(\"tabnet_adult_model_quantized.tflite\") / 1024  # in KB\n","\n","print(f\"Original TFLite Model Size: {tflite_model_size:.2f} KB\")\n","print(f\"Quantized TFLite Model Size: {quantized_tflite_model_size:.2f} KB\")\n","\n","print(\"\\n===== FINAL RESULTS =====\")\n","print(f\"Test Accuracy before Quantization: {test_acc * 100:.2f}%\")\n","print(f\"Test Loss before Quantization: {test_loss * 10:.2f}%\")\n","print(f\"Test Accuracy after Quantization: {quantized_acc * 100:.2f}%\")\n","print(f\"Original TFLite Model Size: {tflite_model_size:.2f} KB\")\n","print(f\"Quantized TFLite Model Size: {quantized_tflite_model_size:.2f} KB\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SunXWz3MiGq1","executionInfo":{"status":"ok","timestamp":1741720942295,"user_tz":-330,"elapsed":5336,"user":{"displayName":"Devapriya Jathin","userId":"00485171850137738167"}},"outputId":"c3fa636a-8b39-4781-8407-911b8bfa389d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved artifact at '/tmp/tmpm6_yc8wg'. The following endpoints are available:\n","\n","* Endpoint 'serve'\n","  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 100), dtype=tf.float32, name=None)\n","Output Type:\n","  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n","Captures:\n","  135567640854352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567640841296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638512080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638513040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567640841872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567640843024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638512464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638511696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638512848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638514192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638514000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638511888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638513808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638513232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638514960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638514384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638515344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638515728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638512656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638512272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638516304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638515536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638516688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638516496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638517072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638515152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638516880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638517648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638516112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638515920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638518032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  135567638517840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","Quantized TFLite model successfully saved as tabnet_adult_model_quantized.tflite\n","\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8546 - loss: 0.4047\n","Test Accuracy before Post-Training Quantization: 0.8534\n","Test Loss before Post-Training Quantization: 0.4052\n","Test Accuracy after Post-Training Quantization: 0.8532\n","Original TFLite Model Size: 265.80 KB\n","Quantized TFLite Model Size: 148.21 KB\n","\n","===== FINAL RESULTS =====\n","Test Accuracy before Quantization: 85.34%\n","Test Loss before Quantization: 4.05%\n","Test Accuracy after Quantization: 85.32%\n","Original TFLite Model Size: 265.80 KB\n","Quantized TFLite Model Size: 148.21 KB\n"]}]}]}